{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzu1 dataloader is ready\n",
      "zzu3 dataloader is ready\n",
      "xy_gs_nm dataloader is ready\n",
      "hb dataloader is ready\n",
      "xj dataloader is ready\n",
      "upenn dataloader is ready\n",
      "val dataloader is ready\n",
      "######################################top_k: 512, Fold: 0, relu:True######################\n",
      "\n",
      "........Validation: grade: 0.842, IDH: 0.863, 1p_19q: 0.766  \n",
      "\n",
      "........Internal  : grade: 0.837, IDH: 0.867, 1p_19q: 0.800  \n",
      "\n",
      "........External  : grade: 0.847, IDH: 0.899, 1p_19q: 0.743  \n",
      "\n",
      "........Prospective: grade: 0.849, IDH: 0.891, 1p_19q: 0.833  \n",
      "\n",
      "zzu1 dataloader is ready\n",
      "zzu3 dataloader is ready\n",
      "xy_gs_nm dataloader is ready\n",
      "hb dataloader is ready\n",
      "xj dataloader is ready\n",
      "upenn dataloader is ready\n",
      "val dataloader is ready\n",
      "######################################top_k: 512, Fold: 1, relu:True######################\n",
      "\n",
      "........Validation: grade: 0.832, IDH: 0.899, 1p_19q: 0.854  \n",
      "\n",
      "........Internal  : grade: 0.840, IDH: 0.856, 1p_19q: 0.873  \n",
      "\n",
      "........External  : grade: 0.846, IDH: 0.896, 1p_19q: 0.810  \n",
      "\n",
      "........Prospective: grade: 0.815, IDH: 0.874, 1p_19q: 0.833  \n",
      "\n",
      "zzu1 dataloader is ready\n",
      "zzu3 dataloader is ready\n",
      "xy_gs_nm dataloader is ready\n",
      "hb dataloader is ready\n",
      "xj dataloader is ready\n",
      "upenn dataloader is ready\n",
      "val dataloader is ready\n",
      "######################################top_k: 512, Fold: 2, relu:True######################\n",
      "\n",
      "........Validation: grade: 0.815, IDH: 0.869, 1p_19q: 0.809  \n",
      "\n",
      "........Internal  : grade: 0.802, IDH: 0.844, 1p_19q: 0.755  \n",
      "\n",
      "........External  : grade: 0.877, IDH: 0.899, 1p_19q: 0.752  \n",
      "\n",
      "........Prospective: grade: 0.874, IDH: 0.882, 1p_19q: 0.861  \n",
      "\n",
      "zzu1 dataloader is ready\n",
      "zzu3 dataloader is ready\n",
      "xy_gs_nm dataloader is ready\n",
      "hb dataloader is ready\n",
      "xj dataloader is ready\n",
      "upenn dataloader is ready\n",
      "val dataloader is ready\n",
      "######################################top_k: 512, Fold: 3, relu:True######################\n",
      "\n",
      "........Validation: grade: 0.850, IDH: 0.843, 1p_19q: 0.767  \n",
      "\n",
      "........Internal  : grade: 0.817, IDH: 0.833, 1p_19q: 0.773  \n",
      "\n",
      "........External  : grade: 0.886, IDH: 0.898, 1p_19q: 0.800  \n",
      "\n",
      "........Prospective: grade: 0.866, IDH: 0.874, 1p_19q: 0.833  \n",
      "\n",
      "zzu1 dataloader is ready\n",
      "zzu3 dataloader is ready\n",
      "xy_gs_nm dataloader is ready\n",
      "hb dataloader is ready\n",
      "xj dataloader is ready\n",
      "upenn dataloader is ready\n",
      "val dataloader is ready\n",
      "######################################top_k: 512, Fold: 4, relu:True######################\n",
      "\n",
      "........Validation: grade: 0.800, IDH: 0.869, 1p_19q: 0.791  \n",
      "\n",
      "........Internal  : grade: 0.802, IDH: 0.856, 1p_19q: 0.791  \n",
      "\n",
      "........External  : grade: 0.843, IDH: 0.874, 1p_19q: 0.733  \n",
      "\n",
      "........Prospective: grade: 0.874, IDH: 0.849, 1p_19q: 0.861  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "from torch.autograd import Variable\n",
    "from model.model import IClassifier,fusionmodel\n",
    "warnings.filterwarnings('ignore')\n",
    "from datasets.dataset import My_features_Dataset\n",
    "import torch.nn.functional as F               \n",
    "\n",
    "def validate_one_epoch(test_loader,dataset,net7, net8,net9,device,output_logist = False):###grade_features_index,IDH_features_index,p1_19qs_features_index  \n",
    "    \n",
    "    \n",
    "    net7.eval()\n",
    "    net8.eval()\n",
    "    net9.eval()\n",
    "    results = []\n",
    "    B = torch.tensor([2])\n",
    "    # with torch.no_grad():\n",
    "   \n",
    "\n",
    "    test_acc_grade_type3 = 0\n",
    "    test_acc_IDH_type3= 0\n",
    "    test_acc_p1_19q_type3 = 0\n",
    "    test_num_grade = 0\n",
    "    test_num_IDH = 0\n",
    "    test_num_p1_19q = 0\n",
    "    for center1, loader in test_loader.items():\n",
    "        for test_data in loader:\n",
    "            Grade_Features_type0, IDH_Features_type0, p1_19q_Features_type0_, Grade_Features_type1, IDH_Features_type1, p1_19q_Features_type1_,Grade_Features_type2, IDH_Features_type2, p1_19q_Features_type2_, id, IDH, p1_19q_, grade = test_data\n",
    "\n",
    "            grade = torch.squeeze(grade)\n",
    "            grade_features_type0 = torch.squeeze(Grade_Features_type0)\n",
    "            grade_features_type1 = torch.squeeze(Grade_Features_type1)\n",
    "            grade_features_type2 = torch.squeeze(Grade_Features_type2)\n",
    "            \n",
    "            # grade_features_type2 = torch.cat([grade_features_type0, grade_features_type1], axis=1)\n",
    "            logits_type3 = net7(grade_features_type0.to(device), grade_features_type1.to(device), grade_features_type2.to(device))\n",
    "            logits_grade_type3 = torch.squeeze(logits_type3)\n",
    "            predict_y_type3 = torch.ge(torch.sigmoid(logits_type3), 0.5).float()\n",
    "            test_acc_grade_type3 += torch.eq(predict_y_type3, grade.float().to(device)).sum().item()\n",
    "\n",
    "            test_num_grade += 1\n",
    "        \n",
    "\n",
    "\n",
    "            IDH = torch.squeeze(IDH)\n",
    "            IDH_features_type0 = torch.squeeze(IDH_Features_type0)\n",
    "            IDH_features_type1 = torch.squeeze(IDH_Features_type1)\n",
    "            IDH_features_type2 = torch.squeeze(IDH_Features_type2)\n",
    "            logits_type3 = net8(IDH_features_type0.to(device), IDH_features_type1.to(device), IDH_features_type2.to(device))\n",
    "            logits_idh_type3 = torch.squeeze(logits_type3)\n",
    "            predict_y_type3 = torch.ge(torch.sigmoid(logits_type3), 0.5).float()\n",
    "            test_acc_IDH_type3 += torch.eq(predict_y_type3, IDH.float().to(device)).sum().item()\n",
    "\n",
    "            test_num_IDH += 1\n",
    "\n",
    "\n",
    "\n",
    "            if center1 != \"upenn\":\n",
    "                \n",
    "                p1_19qs_features_type0 = torch.squeeze(p1_19q_Features_type0_)\n",
    "                p1_19qs_features_type1 = torch.squeeze(p1_19q_Features_type1_)\n",
    "                p1_19qs_features_type2 = torch.squeeze(p1_19q_Features_type2_)\n",
    "               \n",
    "                logits_type3 = net9(p1_19qs_features_type0.to(device), p1_19qs_features_type1.to(device), p1_19qs_features_type2.to(device))\n",
    "                logits_p119q_type3 = torch.squeeze(logits_type3)\n",
    "\n",
    "                if p1_19q_ != B:\n",
    "                    p1_19qs = torch.squeeze(p1_19q_[~np.isin(p1_19q_, B)])\n",
    "                    logits_type3_ = torch.squeeze(logits_type3[~np.isin(p1_19q_, B)])\n",
    "                    predict_y_type3 = torch.ge(torch.sigmoid(logits_type3_), 0.5).float()\n",
    "                    test_acc_p1_19q_type3 += torch.eq(predict_y_type3, p1_19qs.float().to(device)).sum().item()\n",
    "                    test_num_p1_19q += 1\n",
    "\n",
    "\n",
    "            results.append([\n",
    "                torch.squeeze(id).detach().numpy(), \n",
    "                torch.sigmoid(logits_grade_type3).detach().numpy(), grade.detach().numpy(), \n",
    "                torch.sigmoid(logits_idh_type3).detach().numpy(), IDH.detach().numpy(), \n",
    "                torch.sigmoid(logits_p119q_type3).detach().numpy() if p1_19q_ != B  else None, \n",
    "                torch.squeeze(p1_19q_).detach().numpy() ,\n",
    "                center1\n",
    "            ])\n",
    "   \n",
    "\n",
    "\n",
    "    test_accurate_grade_type3 = test_acc_grade_type3  / test_num_grade\n",
    "    test_accurate_IDH_type3 = test_acc_IDH_type3 / test_num_IDH\n",
    "\n",
    "    \n",
    "    test_accurate_1p_19q_type3 = test_acc_p1_19q_type3  / test_num_p1_19q\n",
    "\n",
    "       \n",
    "    print(f'........{dataset:<10}: grade: {test_accurate_grade_type3:.3f}, IDH: {test_accurate_IDH_type3:.3f}, 1p_19q: {test_accurate_1p_19q_type3:.3f}  \\n')\n",
    "    # print(f'Flair , test_accuracy_grade: {test_accurate_grade_type1:.3f}, test_accuracy_IDH:{test_accurate_IDH_type1:.3f}, test_accuracy_1p_19q: {test_accurate_1p_19q_type1:.3f}')\n",
    "    if output_logist:\n",
    "        columns = ['ID', 'logits_grade_type2', 'grade', 'logits_idh_type2', 'IDH', 'logits_p119q_type2', 'p1_19qs',\"center\"]\n",
    "        results_df = pd.DataFrame(results, columns=columns)\n",
    "        results_df[\"dataset\"] = dataset\n",
    "        \n",
    "        return results_df\n",
    "    else:\n",
    "        return test_accurate_grade_type3,test_accurate_IDH_type3,test_accurate_1p_19q_type3\n",
    "\n",
    "batch_size = 1\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "data_root = \"/local/CTimages/brain/code_5mm/data/tumor_slices_2mm/zzu2/03_h5data/features/['T2', 'Flair', 'CET1']\"\n",
    "import pandas as pd\n",
    "# fold = 1\n",
    "df_all = pd.DataFrame([])\n",
    "for fold in (0,1,2,3,4):\n",
    "    internal_test_image_paths = {\n",
    "        \"zzu1\": os.path.join(data_root, f\"features_fold{fold}_zzu1.h5\")}\n",
    "    prospective_test_image_paths = {\n",
    "        \"zzu3\": os.path.join(data_root, f\"features_fold{fold}_zzu3.h5\")}\n",
    "    external_test_image_paths ={\n",
    "        \"xy_gs_nm\": os.path.join(data_root, f\"features_fold{fold}_xy_gs_nm.h5\"),\n",
    "        \"hb\": os.path.join(data_root, f\"features_fold{fold}_hb.h5\"),\n",
    "        \"xj\": os.path.join(data_root, f\"features_fold{fold}_xj.h5\"),\n",
    "        # \"tcga\": os.path.join(data_root, f\"features_fold{fold}_tcga.h5\"),\n",
    "        \"upenn\": os.path.join(data_root, f\"features_fold{fold}_upenn.h5\")\n",
    "    }\n",
    "    internal_test_loaders = {}\n",
    "    for center, path in internal_test_image_paths.items():\n",
    "        dataset = My_features_Dataset(path)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=nw, pin_memory=True)\n",
    "        internal_test_loaders[center] = loader\n",
    "        print(f\"{center} dataloader is ready\")\n",
    "    prospective_test_loaders = {}\n",
    "    for center, path in prospective_test_image_paths.items():\n",
    "        dataset = My_features_Dataset(path)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=nw, pin_memory=True)\n",
    "        prospective_test_loaders[center] = loader\n",
    "        print(f\"{center} dataloader is ready\")\n",
    "\n",
    "    external_test_loaders = {}\n",
    "    for center, path in external_test_image_paths.items():\n",
    "        dataset = My_features_Dataset(path)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=nw, pin_memory=True)\n",
    "        external_test_loaders[center] = loader\n",
    "        print(f\"{center} dataloader is ready\")\n",
    "    train_image_path = os.path.join(data_root, f\"features_fold{fold}_train.h5\")\n",
    "    train_dataset = My_features_Dataset(train_image_path)\n",
    "    train_num = len(train_dataset)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                    batch_size=batch_size, shuffle=True,\n",
    "                                                    num_workers=nw, pin_memory=True)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    train_dataset_selectfeature = My_features_Dataset(train_image_path,feature_forselection=True)\n",
    "\n",
    "    train_loader_selectfeature = torch.utils.data.DataLoader(train_dataset_selectfeature,\n",
    "                                                    batch_size=len(train_dataset_selectfeature), shuffle=False,\n",
    "                                                num_workers=8)\n",
    "    val_image_paths = {\n",
    "        \"val\": os.path.join(data_root, f\"features_fold{fold}_val.h5\")}\n",
    "    val_test_loaders = {}\n",
    "    for center, path in val_image_paths.items():\n",
    "        dataset = My_features_Dataset(path)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=nw, pin_memory=True)\n",
    "        val_test_loaders[center] = loader\n",
    "        print(f\"{center} dataloader is ready\")\n",
    "    device = \"cpu\"\n",
    "    # top_ks = (100,200,250)\n",
    "    fusion = ['concat','bilinear']\n",
    "\n",
    "    top_k = 512\n",
    "    fusion_layres = 'concat'\n",
    "\n",
    "    relu = True\n",
    "    print(f\"######################################top_k: {top_k}, Fold: {fold}, relu:{relu}######################\\n\")\n",
    "\n",
    "\n",
    "    net7 = fusionmodel(n_classes= 1,fusion_layres = fusion_layres,dropout=0.25,scale_dim1=8,gate_path=1,scale_dim2=8,gate_omic=1,skip=True,relu = relu,top_k =top_k).to(device)\n",
    "    params7 = [p for p in net7.parameters() if p.requires_grad]\n",
    "    optimizer7 = optim.Adam(params7, lr=0.0001)\n",
    "    weights_root = f\"/local/CTimages/brain/code_5mm/data/tumor_slices_2mm/zzu2/03_h5data/features/['T2', 'Flair', 'CET1']/save_concat_reluTrue/fold{fold}/grade/best_weights\"\n",
    "    weights_path1 = os.path.join(weights_root, os.listdir(weights_root).pop())  \n",
    "    net7.load_state_dict(torch.load(weights_path1, map_location='cpu'))\n",
    "\n",
    "    net8 = fusionmodel(n_classes= 1,fusion_layres = fusion_layres,dropout=0.25,scale_dim1=8,gate_path=1,scale_dim2=8,gate_omic=1,skip=True,relu = relu,top_k =top_k).to(device)\n",
    "    params8 = [p for p in net8.parameters() if p.requires_grad]\n",
    "    optimizer8 = optim.Adam(params8, lr=0.0001)\n",
    "    weights_root = f\"/local/CTimages/brain/code_5mm/data/tumor_slices_2mm/zzu2/03_h5data/features/['T2', 'Flair', 'CET1']/save_concat_reluTrue/fold{fold}/IDH/best_weights\"\n",
    "    weights_path1 = os.path.join(weights_root, os.listdir(weights_root).pop())  \n",
    "    net8.load_state_dict(torch.load(weights_path1, map_location='cpu'))\n",
    "\n",
    "    net9 = fusionmodel(n_classes= 1,fusion_layres = fusion_layres,dropout=0.25,scale_dim1=8,gate_path=1,scale_dim2=8,gate_omic=1,skip=True,relu = relu,top_k =top_k).to(device)\n",
    "    params9 = [p for p in net9.parameters() if p.requires_grad]\n",
    "    optimizer9 = optim.Adam(params9, lr=0.0001)\n",
    "    weights_root = f\"/local/CTimages/brain/code_5mm/data/tumor_slices_2mm/zzu2/03_h5data/features/['T2', 'Flair', 'CET1']/save_concat_reluTrue/fold{fold}/p119q/best_weights\"\n",
    "    weights_path1 = os.path.join(weights_root, os.listdir(weights_root).pop())  \n",
    "    net9.load_state_dict(torch.load(weights_path1, map_location='cpu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_val = validate_one_epoch(test_loader=val_test_loaders,dataset= \"Validation\",net7=net7,net8=net8,net9=net9,device= device,output_logist = True)#grade_features_index = grade_features_index,IDH_features_index = IDH_features_index,p1_19qs_features_index = p1_19qs_features_index \n",
    "    # print(\"\\n··················································································································\")\n",
    "    # for center, loader in test_loaders[:2].items():\n",
    "    df_intest = validate_one_epoch(test_loader=internal_test_loaders,dataset= \"Internal\",  net7=net7,net8=net8,net9=net9,device=device,output_logist = True)#,grade_features_index = grade_features_index,IDH_features_index = IDH_features_index,p1_19qs_features_index = p1_19qs_features_index \n",
    "    df_extest = validate_one_epoch(test_loader=external_test_loaders,dataset= \"External\",  net7=net7,net8=net8,net9=net9,device=device,output_logist = True)\n",
    "    df_protest = validate_one_epoch(test_loader=prospective_test_loaders,dataset= \"Prospective\",  net7=net7,net8=net8,net9=net9,device=device,output_logist = True)\n",
    "        # print(\"\\n··················································································································\")\n",
    "    df_fold = pd.concat([df_val,df_intest,df_extest,df_protest])\n",
    "    df_fold[\"Fold\"] = f\"fold{fold}\"\n",
    "    df_all = pd.concat([df_all,df_fold])\n",
    "\n",
    "df_all.to_csv(\"/local/CTimages/brain/code_5mm/data/tumor_slices_2mm/zzu2/03_h5data/features/['T2', 'Flair', 'CET1']/results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
